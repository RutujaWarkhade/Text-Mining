{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60cbbfd8-dbce-4718-915f-32d7f41be9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Home | Kong | factory | for | $ | 6 | millon | \n",
      "----\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Home Kong - GPE - Countries, cities, states\n",
      "$6 - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc8 = nlp(u\"Apple to build a Home Kong factory for $6 millon\")\n",
    "for token in doc8:\n",
    "    print(token.text, end=' | ')\n",
    "print('\\n----')\n",
    "for ent in doc8.ents:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9503d908-6d6c-4103-a999-5ac03775b3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufactures\n"
     ]
    }
   ],
   "source": [
    "#noun chunk\n",
    "#when their is noun in sentence then use noun chuck\n",
    "doc9 = nlp(u\"Autonomous cars shift insurance liability toward manufactures.\")\n",
    "for chunk in doc9.noun_chunks: \n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0495b5d6-b99e-4264-bf86-7482744a5e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red cars\n",
      "higher insurance rates\n"
     ]
    }
   ],
   "source": [
    "doc10 = nlp(u\"Red cars do not carry higher insurance rates.\")\n",
    "for chunk in doc10.noun_chunks:#chunking or grouping the nouns like red car\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f1010-0b4c-4d4e-b916-0380fb37b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "stemming is a somewhat crude method for cataloging related words; it essentialy chops off letters\n",
    "from the end until the stem is reached.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "060d6c3f-91cd-400e-a740-935552ef18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the toolkit and the full Porter Stemmer library\n",
    "import nltk\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e6641c-69eb-47a4-a247-0fba8be98019",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc8fa53-adda-467f-aee0-da389645ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['run','runner','running','ran','runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b24513eb-6542-42ec-b054-e9c7d0bc51c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+' --> '+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8d96d-14de-49e0-a97d-facb531fbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note how the stemmer recognizes \"runner\" as a noun, not a verb form or participle. Also\n",
    "the adverbs \"easily\" and \"fairly\" are stemmed to the \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65ac01ac-b641-4053-b7cd-b84009fb3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "#The Snowball Stemmer requires that you pass a language parameter\n",
    "s_stemmer = SnowballStemmer(language=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51096d31-77c2-46d8-8c91-e5abf07c17e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','runs','easily','fairly']\n",
    "#words = ['generous','generation','generously','generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c02cc704-288c-4701-b4c7-cdbbd736c2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+' --> '+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54103870-05f6-4dad-8288-abda2dfc403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runner it treat as a runner hence it cannot do run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8461b3ba-2e69-423d-9dc4-2faceabcdc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I --> i\n",
      "am --> am\n",
      "meeting --> meet\n",
      "him --> him\n",
      "tomorrow --> tomorrow\n",
      "at --> at\n",
      "the --> the\n",
      "meeting --> meet\n"
     ]
    }
   ],
   "source": [
    "phrase = \"I am meeting him tomorrow at the meeting\"\n",
    "for word in phrase.split():\n",
    "    print(word+' --> '+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f998ad4-b672-4a50-8ae6-0d5406405397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here the word \"meeting\" appears twice- once as a verb, and once as a noun, and yet the stemmer treats both equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f9290-cff3-406b-9441-fc439236ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lemmitization check the contex. then the word in it convert into orginal form which depends on \n",
    "the sentence\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a35e72-ee59-4da5-8f99-869a628bc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7d7af0-b9a1-4464-8c33-9f200d86c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform standard imports:\n",
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe6139a3-2525-4967-a51a-6a0029baba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t SCONJ \t 16950148841647037698 \t because\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t SCONJ \t 10066841407251338481 \t since\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "today \t NOUN \t 11042482332948150395 \t today\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u\"I am runner running in a race because I love to run since I ran today\")\n",
    "for token in doc1:\n",
    "    print(token.text, '\\t', token.pos_, '\\t', token.lemma, '\\t', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19d3eb-dab4-45ae-a9ec-fc1d9a20c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function we are an f-string to format the printed text by setting minimum field\n",
    "widths and adding a left-align to the lemma hash value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb38c29b-8ed5-42ab-86d9-eae762c7504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f\"{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7bffd65-92d4-4fa6-8dcb-f6b6d8afc191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   4690420944186131903    I\n",
      "saw          VERB   11925638236994514241   see\n",
      "eighteen     NUM    9609336664675087640    eighteen\n",
      "mice         NOUN   1384165645700560590    mouse\n",
      "today        NOUN   11042482332948150395   today\n",
      "!            PUNCT  17494803046312582752   !\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"I saw eighteen mice today!\")\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed6f4056-10bc-422f-a4fc-37a0324950ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   4690420944186131903    I\n",
      "am           AUX    10382539506755952630   be\n",
      "meeting      VERB   6880656908171229526    meet\n",
      "him          PRON   1655312771067108281    he\n",
      "tomorrow     NOUN   3573583789758258062    tomorrow\n",
      "at           ADP    11667289587015813222   at\n",
      "the          DET    7425985699627899538    the\n",
      "meeting      NOUN   14798207169164081740   meeting\n",
      ".            PUNCT  12646065887601541794   .\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u\"I am meeting him tomorrow at the meeting.\")\n",
    "show_lemmas(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19213989-9d7c-457c-b455-e8094c3e0221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That         PRON   4380130941430378203    that\n",
      "'s           AUX    10382539506755952630   be\n",
      "an           DET    15099054000809333061   an\n",
      "enormous     ADJ    17917224542039855524   enormous\n",
      "automobile   NOUN   7211811266693931283    automobile\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u\"That's an enormous automobile\")\n",
    "show_lemmas(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c809c6-3274-41c9-b809-c938ec4267a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "stop words words like \"a\" and \"the\" appear so frequently that they don't require tagging as\n",
    "thoroughly as nouns, verbs and modifiers. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c28e9c-b2bf-4994-a523-be7de78f1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words are all words rather than nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8085a149-2193-41dc-926c-9b25ebe7668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform standars imports\n",
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "107cfbe8-dc5d-4779-9023-3b39378b0a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'still', 'after', 'twelve', 'whenever', 'together', 'anyone', 'due', 'next', 'us', 'empty', 'many', 'so', 'in', 'sometime', 'much', 'serious', 'name', 'thus', 'hence', 'ten', 'made', 'am', '’s', 'its', 'hereupon', 'indeed', 'front', 'it', 'everywhere', 'such', 'noone', 'you', 'because', 'down', 'yourself', 'becomes', 'really', 'just', 'thereupon', 'whither', 'anywhere', 'yourselves', 'same', 'several', \"'s\", 'or', 'through', 'there', 'former', 'thru', 'my', 'your', 'back', 'without', 'ca', \"'ve\", 'was', \"n't\", 'whose', 'then', 'becoming', 'take', 'cannot', 'her', 'somewhere', 'him', 'is', 'already', 'here', 'during', 'our', 'mine', 'latterly', 'more', 'neither', 'almost', 'make', 'enough', 'whereby', 'among', 'when', 'four', 'out', 'why', 'every', 'few', 'using', 'perhaps', 'afterwards', 'may', 'yours', 'part', 'beyond', 'anyway', \"'m\", 'not', 're', 'which', 'across', 'most', '’d', 'another', 'rather', 'bottom', 'amount', 'did', 'twenty', 'along', 'side', 'meanwhile', 'give', 'them', 'these', 'any', 'up', 'seemed', 'via', 'say', 'everyone', 'into', 'become', 'formerly', 'again', 'amongst', 'although', 'being', 'three', 'least', 'what', 'therefore', 'always', 'show', 'whom', 'five', 'however', 'anything', 'myself', 'n‘t', 'other', 'namely', 'see', 'onto', 'nothing', 'would', 'thence', '’m', 'were', 'over', 'besides', 'under', 'does', 'very', 'a', 'anyhow', 'hundred', 'against', 'nowhere', 'once', 'the', 'less', 'they', 'herself', 'no', 'who', '‘d', 'around', '‘ve', 'wherever', 'should', \"'re\", 'whereas', 'please', 'one', 'mostly', 'herein', 'something', 'throughout', 'hereby', 'move', 'since', 'between', 'have', 'only', 'could', 'quite', 'until', 'regarding', 'get', '‘s', 'whereafter', 'can', 'nine', 'first', 'that', 'about', 'done', 'n’t', 'go', 'none', 'above', 'an', 'everything', 'as', '‘ll', 'third', 'full', 'has', 'used', 'to', 'and', 'nobody', 'toward', 'where', \"'d\", 'somehow', 'but', 'those', 'also', 'we', 'their', 'be', 'top', '‘m', 'seems', 'hers', 'itself', 'whereupon', 'off', 'unless', 'might', 'even', 'upon', 'wherein', 'than', 'well', 'both', 'some', '‘re', 'behind', 'often', 'various', 'i', 'two', 'by', 'elsewhere', 'hereafter', 'call', 'with', 'himself', '’re', 'whoever', 'whatever', 'fifty', 'yet', 'from', 'ourselves', 'someone', 'eight', '’ll', 'nor', 'beforehand', 'fifteen', 'further', 'otherwise', 'had', 'except', 'me', 'others', 'whence', 'of', 'ours', 'alone', 'she', 'he', 'either', 'below', 'became', 'six', 'thereafter', 'within', 'forty', 'last', 'sometimes', 'seem', 'moreover', 'will', 'beside', 'each', 'whole', 'per', 'own', 'towards', 'themselves', 'keep', 'never', 'sixty', 'now', 'his', 'are', 'too', 'else', 'though', '’ve', 'therein', 'put', 'before', 'nevertheless', 'for', 'on', 'must', 'thereby', 'how', 'seeming', 'been', 'eleven', 'all', 'at', 'while', 'do', 'doing', 'ever', 'this', 'if', \"'ll\", 'latter', 'whether'}\n"
     ]
    }
   ],
   "source": [
    "#print the set of all spacy stop words\n",
    "print(nlp.Defaults.stop_words)\n",
    "#326 stop words their are in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84f281a0-0bc5-446f-a13a-4f5a2ec51155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e44a94-9783-4065-9905-089cbc85e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see if a word is stop word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "421d6569-c05e-4da5-8c7d-78b6d7636f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2cc3068-2670-4d59-a8ff-6b94f2cb0c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db477fd2-7e0b-42d1-9941-052c62e4a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7121965-160d-49b8-ad47-835d2540dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the word to the set of stop words. Use lowercase!\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "#set the stop_word tag on the lexeme\n",
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50a05ada-e065-4e2d-818e-7fa98bfad9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29c101a9-bd85-4c7e-8100-d00640dc0068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "248cf1ec-c058-45ea-b0f5-59b4d19963cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove a stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f1e3d89-5536-4511-bc0f-1220d533490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let consider beyound is stop words\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "#Remove the stop_word tag from the lexeme\n",
    "nlp.vocab['beyond'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb95528-8226-40ca-bc45-d6d634a79c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
